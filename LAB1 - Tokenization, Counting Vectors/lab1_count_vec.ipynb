{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplemma import text_lemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = None\n",
    "with open(\"stopwords.txt\", \"r\") as stop_file:\n",
    "    stop_words = set(stop_file.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"Â\", \"a\")\n",
    "    text = text.replace(\"â\", \"a\")\n",
    "    text = text.replace(\"î\", \"i\")\n",
    "    text = text.replace(\"Î\", \"ı\")\n",
    "    text = text.replace(\"İ\", \"i\")\n",
    "    text = text.replace(\"I\", \"ı\")\n",
    "    text = text.replace(u\"\\u00A0\", \" \")\n",
    "    text = text.replace(\"|\", \" \")\n",
    "\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", \" \", text)\n",
    "    text = re.sub(r\"(.)\\1+\", r\"\\1\\1\", text)\n",
    "    text = re.sub(r\"https?:\\/\\/\\S+\", \" \", text)\n",
    "    text = re.sub(r\"http?:\\/\\/\\S+\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"#(\\w+)\", \" \", text)\n",
    "    text = re.sub(r\"^\\x00-\\x7F]+\", \" \", text)\n",
    "    text = re.sub(r\"[^A-Za-zâîığüşöçİĞÜŞÖÇ]+\", \" \", text)\n",
    "    text = re.sub(r\"((https://[^\\s]+))\", \" \", text)\n",
    "\n",
    "    text = \" \".join(text.lower().strip().split())\n",
    "    text = text_lemmatizer(text, lang=\"tr\")\n",
    "\n",
    "    return \" \".join([word for word in text if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumle = \"Hey! Naber???İyilik, senden... Ben de iyiyim.Çocuk filmi Kirpi Sonic filminin devam halkası olan yapımda, insan biçiminde bir kirpi olan Sonic'in atıldığı maceralar konu ediliyor. Green Hills’e yerleşen Sonic’in tek isteği, gerçek bir kahraman olması için gereken özelliklere sahip olduğunu kanıtlayabilmektir. Sonic’in sınavı, Dr. Robotnik’in ortağı Knuckes ile birlikte medeniyetleri yok edebilecek güce sahip bir zümrüdü aramak için geri dönmesiyle başlar. Zümrüdün yanlış ellere geçmesini engellemek için Sonic, yardımcısı Tails ile birlikte macera dolu bir yolculuğa çıkar.\"\n",
    "clean_text(cumle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"filmveriseti.xlsx\") \n",
    "# https://www.kaggle.com/code/furkanyeter/content-based-recommendation-system-turkish-movie/data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4][\"ozet ve detaylar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4][\"tur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[4][\"tur\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tur_list\"] = df[\"tur\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4][\"tur_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row(row):\n",
    "    ozet = clean_text(row[\"ozet ve detaylar\"])\n",
    "    tur = row[\"tur_list\"]\n",
    "    return ozet + \" \" + \" \".join(tur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_row(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean\"] = df.apply(lambda row: clean_row(row), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range(3):\n",
    "    rand_idx = random.randrange(len(df))\n",
    "    ozet = df.iloc[rand_idx][\"ozet ve detaylar\"]\n",
    "    print(\"Orijinal:\")\n",
    "    print(ozet + \"\\n\")\n",
    "    print(\"Temizlenmiş:\")\n",
    "    print(df.iloc[rand_idx][\"clean\"])\n",
    "    print(\"/\" * 50 + \"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sözlük oluşturma başlıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelime2index = {}\n",
    "index2kelime = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelime2index[\"<UNK>\"] = 0\n",
    "index2kelime[0] = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col = df[\"clean\"]\n",
    "clean_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for doc in clean_col.values:\n",
    "    for token in doc.split():\n",
    "        if token in kelime2index:\n",
    "            continue\n",
    "        \n",
    "        kelime2index[token] = i\n",
    "        index2kelime[i] = token\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kelime2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2kelime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kelime2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sayma vektörleri (Counting vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_mat = np.zeros((len(df), len(kelime2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(clean_col.values):\n",
    "    for token in doc.split():\n",
    "        token_index = kelime2index[token]\n",
    "        doc_mat[i][token_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorgular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "film_indexi = random.randrange(len(df))\n",
    "film = df.iloc[film_indexi]\n",
    "film[\"film adi\"], film[\"ozet ve detaylar\"], film[\"tur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benzerlikler = []\n",
    "sorgu_film = doc_mat[film_indexi]\n",
    "for vec in doc_mat:\n",
    "    benzerlik = cos_sim(sorgu_film, vec)\n",
    "    benzerlikler.append(benzerlik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [1, 5, 4, 2]\n",
    "print(np.array(test_list).argsort()[:2])\n",
    "print((- np.array(test_list)).argsort()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en yakın 5 film\n",
    "top5_film_indexleri = (- np.array(benzerlikler)).argsort()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top5_film_indexleri:\n",
    "    film = df.iloc[i]\n",
    "    print(film[\"film adi\"], film[\"ozet ve detaylar\"], film[\"tur\"])\n",
    "    print(\" - \" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_film(row_index):\n",
    "    film = df.iloc[row_index]\n",
    "    adi = film[\"film adi\"]\n",
    "    turu = \", \".join(film[\"tur_list\"])\n",
    "    ozet = film[\"ozet ve detaylar\"]\n",
    "    if len(ozet) > 150:\n",
    "        ozet = ozet[:150] + \"...\"\n",
    "\n",
    "    print(f\"Film adı: {adi} \\nTürü: {turu} \\nÖzeti: {ozet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benzerlerini_bul(film_adi, benzer_film_sayisi):\n",
    "    film_indexi = df[df[\"film adi\"] == film_adi].index[0]\n",
    "    print(\"Aranan Film:\")\n",
    "    print_film(film_indexi)\n",
    "    print(\" * \" * 20)\n",
    "    print(\" * \" * 20)\n",
    "\n",
    "    benzerlikler = []\n",
    "    sorgu_film = doc_mat[film_indexi]\n",
    "    for vec in doc_mat:\n",
    "        benzerlik = cos_sim(sorgu_film, vec)\n",
    "        benzerlikler.append(benzerlik)\n",
    "    \n",
    "    en_benzer_film_indexleri = (- np.array(benzerlikler)).argsort()[:benzer_film_sayisi + 1]\n",
    "    print(\"Benzer Filmler:\\n\")\n",
    "    for i in en_benzer_film_indexleri[1:]:\n",
    "        print_film(i)\n",
    "        print(\" - \" * 20)\n",
    "        print(\" - \" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benzerlerini_bul(\"Kirpi Sonic 2\", 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
