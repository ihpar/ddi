{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"filmler_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = df[\"clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "idx2word = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for cell in clean:\n",
    "    words = cell.split()\n",
    "    for word in words:\n",
    "        if word in word2idx:\n",
    "            continue\n",
    "        word2idx[word] = i\n",
    "        idx2word[i] = word\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_sayisi = len(clean)\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmler = np.zeros((film_sayisi, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cell in enumerate(clean):\n",
    "    words = cell.split()\n",
    "    for word in words:\n",
    "        wordIndex = word2idx[word]\n",
    "        filmler[i][wordIndex] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmler[7][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_frequencies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 5 dk sürebilir \n",
    "for word in word2idx:\n",
    "    doc_count = 0\n",
    "    for film in clean:\n",
    "        if word in film:\n",
    "            doc_count += 1\n",
    "    \n",
    "    doc_frequencies[word] = doc_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_frequencies = sorted(doc_frequencies, key=doc_frequencies.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sorted_frequencies[:10]:\n",
    "    print(word, doc_frequencies[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sorted_frequencies[150:160]:\n",
    "    print(word, doc_frequencies[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sorted_frequencies[-10:]:\n",
    "    print(word, doc_frequencies[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - 5 dk sürebilir\n",
    "filmler_tf_idf = np.zeros((film_sayisi, vocab_size))\n",
    "film_sayisi = len(clean)\n",
    "\n",
    "for i, film in enumerate(filmler):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i} inci film işleniyor...\")\n",
    "    for j, tf in enumerate(film):\n",
    "        idf = 0\n",
    "        if tf > 0:\n",
    "            idf = np.log(film_sayisi / (doc_frequencies[idx2word[j]] + 1)) + 1\n",
    "        tf_idf_score = tf * idf\n",
    "        filmler_tf_idf[i][j] = tf_idf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filmler_tf_idf[0][:10])\n",
    "print(filmler[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def film_2_str(row_index):\n",
    "    film = df.iloc[row_index]\n",
    "    adi = film['film adi']\n",
    "    turu = film['tur']\n",
    "    ozet = film['ozet ve detaylar']\n",
    "    if len(ozet) > 150:\n",
    "        ozet = ozet[:150] + \"...\"\n",
    "\n",
    "    return f\"Film adı: {adi} \\nTürü: {turu} \\nÖzeti: {ozet}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(film_2_str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_films(film_adi, benzer_film_sayisi):\n",
    "    film_indexi = df[df[\"film adi\"] == film_adi].index[0]\n",
    "    print(\"Aranan Film:\")\n",
    "    print(film_2_str(film_indexi))\n",
    "    print()\n",
    "    print(\"* \" * 30)\n",
    "    print()\n",
    "\n",
    "    benzerlikler = []\n",
    "    sorgu_film = filmler_tf_idf[film_indexi]\n",
    "    for vec in filmler_tf_idf:\n",
    "        benzerlik = cos_sim(sorgu_film, vec)\n",
    "        benzerlikler.append(benzerlik)\n",
    "    \n",
    "    en_benzer_film_indexleri = (- np.array(benzerlikler)).argsort()[:benzer_film_sayisi + 1]\n",
    "    print(\"Benzer Filmler:\\n\")\n",
    "    for i, film_idx in enumerate(en_benzer_film_indexleri[1:]):\n",
    "        print(str(i+1) + \") \" + film_2_str(film_idx))\n",
    "        print()\n",
    "        print(\"- \" * 20)\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:10][\"film adi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_films(\"Kirpi Sonic 2\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a508892ad0418bbbef2f3796edd4c06527622cb95cdcc5e9525e8332085ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
