{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/emreokcular/turkish-song-lyrics\n",
    "df = pd.read_csv(\"turkish_song_lyrics.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"singer\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"singer\"])[\"song\"].count().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.singer.value_counts().plot.bar(title=\"Sanatçıya Göre Şarkı Sayıları\", figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarki_sozleri = df.lyrics.to_numpy()\n",
    "sarki_sozleri[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satirlar = sarki_sozleri[0].lower().split(\"\\n\")\n",
    "satirlar[10:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = {}  # sadece satir basi kelimelerin olasilik dict'i\n",
    "A1 = {}  # onceki kelimeden sonra gelebilecek diğer kelimelerin olasilik dict'i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "satir_sonu = \"<END>\"\n",
    "\n",
    "for sarki_sozu in sarki_sozleri:  # sarki_sozu : tek bir sarkinin tum satirlari\n",
    "    satirlar = sarki_sozu.lower().split(\"\\n\")  # satirlar : bir sarkinin satirlari\n",
    "\n",
    "    for satir in satirlar:  # bir sarkinin 1 satiri\n",
    "        # satirdaki kelimeler (kucuk harf, noktalamasiz)\n",
    "        tokens = satir.translate(str.maketrans(\n",
    "            \"\", \"\", string.punctuation)).split()\n",
    "        token_sayisi = len(tokens)  # satirdaki kelime sayisi\n",
    "\n",
    "        for i in range(token_sayisi):\n",
    "            token = tokens[i]  # token : satirdaki kelime\n",
    "            if i == 0:  # ilk kelime icin;\n",
    "                # pi dict'inde bu kelime onceden gectiyse frekansini 1 arttir\n",
    "                # eger gecmediyse frekansini 1 yap\n",
    "                pi[token] = pi.get(token, 0) + 1\n",
    "            else:\n",
    "                onceki_token = tokens[i-1]  # bir onceki kelimeyi al\n",
    "                if onceki_token not in A1:\n",
    "                    # bir onceki kelime A1'de yoksa ona ait bir list yarat\n",
    "                    A1[onceki_token] = []\n",
    "\n",
    "                # A1'de oncekli kelimeye ait listeye simdiki kelimeyi ekle\n",
    "                A1[onceki_token].append(token)\n",
    "\n",
    "                if i == (token_sayisi - 1):  # satir sonuna geldiysek\n",
    "                    # satirin son kelimesi A1'de yoksa A1'de son kelime icin bir list yarat\n",
    "                    if token not in A1:\n",
    "                        A1[token] = []\n",
    "                    # satirin son kelimesinin listesine satir sonu sembolu ekle\n",
    "                    A1[token].append(satir_sonu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_sorted = sorted(pi, key=pi.get, reverse=True)\n",
    "\n",
    "for token in pi_sorted[:10]:\n",
    "    print(token, \": \", pi[token])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in A1:\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(k, \": \", A1[k][:10], \"\\n\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_total = sum(pi.values())\n",
    "pi_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in pi:\n",
    "    # pi dict'indeki frekanslari normalize ediyoruz\n",
    "    pi[token] = pi[token] / pi_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for token in pi:\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(token, pi[token])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_total = sum(pi.values())\n",
    "pi_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1'deki key, value ikililerinin formati şu an:\n",
    "\n",
    "# gelirdi :  ['<END>', '<END>', 'ayrılıksa', 'elimizden', '<END>', '<END>', 'sevişirdik', '<END>', 'her', '<END>', ...]\n",
    "\n",
    "# Bunlari dönüştüreceğimiz format:\n",
    "\n",
    "# gelirdi :  {'<END>': 0.3, 'ayrılıksa': 0.01, 'elimizden': 0.13, ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in A1:  # token : gelirdi\n",
    "    # tokens_list : ['<END>', '<END>', 'ayrılıksa', ...]\n",
    "    tokens_list = A1[token]\n",
    "    num_tokens = len(tokens_list)\n",
    "\n",
    "    tokens_dict = {}\n",
    "    for t in tokens_list:  # t : '<END>'\n",
    "        # tokens_dict : { '<END>':7, ... }\n",
    "        tokens_dict[t] = tokens_dict.get(t, 0) + 1\n",
    "\n",
    "    for t in tokens_dict:  # tokens_dict'teki butun sayilari normalize et\n",
    "        tokens_dict[t] = tokens_dict[t] / num_tokens\n",
    "\n",
    "    A1[token] = tokens_dict  # A1'deki value'ları artık list değil; dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A1[\"giderdi\"], \"\\n\")\n",
    "print(sum(A1[\"giderdi\"].values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelime_sec(d):\n",
    "    \"\"\"\n",
    "    d: {'<END>': 0.7, 'her': 0.1, 'test': 0.2} gibi bir dict'ten \n",
    "    dict'teki olasiliklara göre rastgele bir kelime seçecek.\n",
    "    '<END>'in seçilme olasiligi 0.7, 'test'in secilme olasiligi 0.2,\n",
    "    'her'in secilme olasiligi 0.1 olacak.\n",
    "    \"\"\"\n",
    "    rastgele_sayi = np.random.random()  # rastgele_sayi: [0, 1)\n",
    "    esik = 0\n",
    "    for token, prob in d.items():\n",
    "        esik += prob\n",
    "        if esik >= rastgele_sayi:\n",
    "            return token\n",
    "\n",
    "    raise Exception(\"kelime_sec fonksiyonu yanlis calisiyor!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    token = kelime_sec(pi)\n",
    "    print(token, pi[token])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    token = kelime_sec(A1[\"gelirdi\"])\n",
    "    print(token, A1[\"gelirdi\"][token])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soz_yaz(satir_sayisi):\n",
    "    satirlar = []\n",
    "    for i in range(satir_sayisi):\n",
    "        satir = []\n",
    "        ilk_kelime = kelime_sec(pi)\n",
    "        satir.append(ilk_kelime)\n",
    "\n",
    "        onceki_kelime = ilk_kelime\n",
    "        while True:\n",
    "            yeni_kelime = kelime_sec(A1[onceki_kelime])\n",
    "            if yeni_kelime == satir_sonu:\n",
    "                satirlar.append(\" \".join(satir))\n",
    "                break\n",
    "            satir.append(yeni_kelime)\n",
    "            onceki_kelime = yeni_kelime\n",
    "\n",
    "    return \"\\n\".join(satirlar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soz_yaz(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Derece Markov Modelleri ile nasıl sonuçlar elde edebiliriz?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pi, A1, ve A2 matrislerini oluşturalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(k, v, di):\n",
    "    \"\"\"\n",
    "    From: https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference\n",
    "    Arguments are passed by assignment. The rationale behind this is twofold:\n",
    "\n",
    "    1. the parameter passed in is actually a reference to an object (but the reference is passed by value)\n",
    "    2. some data types are mutable, but others aren't\n",
    "    So:\n",
    "\n",
    "    * If you pass a mutable object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object.\n",
    "\n",
    "    * If you pass an immutable object to a method, you still can't rebind the outer reference, and you can't even mutate the object.\n",
    "\n",
    "    Ex: \n",
    "    my_dict = {}\n",
    "    add2dict(\"x\", 5, my_dict)\n",
    "    my_dict == {\"x\": [5]}\n",
    "\n",
    "    add2dict(\"x\", 7, my_dict)\n",
    "    my_dict == {\"x\": [5, 7]}\n",
    "\n",
    "    my_dict = {}\n",
    "    add2dict((\"x\", \"y\"), 2, my_dict) => tuple'lar hashlenebilen yapilardir. dict'lere key olabilirler. \n",
    "    my_dict == {(\"x\", \"y\"): [5]}\n",
    "    \"\"\"\n",
    "    if k not in di:\n",
    "        di[k] = []\n",
    "    di[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satir_sonu = \"<END>\"\n",
    "\n",
    "A_0, A_1, A_2 = {}, {}, {} # A_0: pi, A_1: 1. derece Mark. M, A_2: 2. derece Mark. M\n",
    "\n",
    "for sarki_sozu in sarki_sozleri: # sarki_sozu : tek bir sarkinin tum satirlari\n",
    "    satirlar = sarki_sozu.lower().split(\"\\n\") # satirlar : bir sarkinin satirlari\n",
    "    \n",
    "    for satir in satirlar: # bir sarkinin 1 satiri\n",
    "        # satirdaki kelimeler (kucuk harf, noktalamasiz)\n",
    "        tokens = satir.translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "        token_sayisi = len(tokens) # satirdaki kelime sayisi\n",
    "        \n",
    "        for i in range(token_sayisi):\n",
    "            t = tokens[i] # token : satirdaki kelime\n",
    "            if i == 0: # ilk kelime icin;\n",
    "                # A_0 (pi) dict'inde bu kelime onceden gectiyse frekansini 1 arttir\n",
    "                # eger gecmediyse frekansini 1 yap\n",
    "                A_0[t] = A_0.get(t, 0) + 1\n",
    "\n",
    "            if i == 1: # 2. kelimedeyiz \n",
    "                add2dict(tokens[i - 1], t, A_1)\n",
    "\n",
    "            if i > 1: # 3. ve sonrasındaki bir kelimedeyiz\n",
    "                add2dict((tokens[i - 2], tokens[i - 1]), t, A_2)\n",
    "            \n",
    "            if i == (token_sayisi - 1): # satirin son kelimesine geldik\n",
    "                if token_sayisi == 1: # satirda sadece 1 kelime varsa\n",
    "                    add2dict(t, satir_sonu, A_1)\n",
    "                else: # satirda 1'den fazla kelime var\n",
    "                    add2dict((tokens[i - 1], t), satir_sonu, A_2)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_0:\n",
    "    if i == 4:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_0[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_1:\n",
    "    if i == 5:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_1[t][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_2:\n",
    "    if i == 5:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_2[t][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_0_total = sum(A_0.values())\n",
    "for token in A_0:\n",
    "    # A_0 dict'indeki frekanslari normalize ediyoruz\n",
    "    A_0[token] = A_0[token] / A_0_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_0:\n",
    "    if i == 4:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_0[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in A_1:  # token : gelirdi\n",
    "    # tokens_list : ['<END>', '<END>', 'ayrılıksa', ...]\n",
    "    tokens_list = A_1[token]\n",
    "    num_tokens = len(tokens_list)\n",
    "\n",
    "    tokens_dict = {}\n",
    "    for t in tokens_list:  # t : '<END>'\n",
    "        # tokens_dict : { '<END>':7, ... }\n",
    "        tokens_dict[t] = tokens_dict.get(t, 0) + 1\n",
    "\n",
    "    for t in tokens_dict:  # tokens_dict'teki butun sayilari normalize et\n",
    "        tokens_dict[t] = tokens_dict[t] / num_tokens\n",
    "\n",
    "    A_1[token] = tokens_dict  # A1'deki value'ları artık list değil; dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_1[\"bir\"]:\n",
    "    if i == 5:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_1[\"bir\"][t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ikili in A_2:  # ikili : (tren, gelirdi)\n",
    "    # tokens_list : ['<END>', '<END>', 'hızlıca', ...]\n",
    "    tokens_list = A_2[ikili]\n",
    "    num_tokens = len(tokens_list)\n",
    "\n",
    "    tokens_dict = {}\n",
    "    for t in tokens_list:  # t : '<END>'\n",
    "        # tokens_dict : { '<END>':7, ... }\n",
    "        tokens_dict[t] = tokens_dict.get(t, 0) + 1\n",
    "\n",
    "    for t in tokens_dict:  # tokens_dict'teki butun sayilari normalize et\n",
    "        tokens_dict[t] = tokens_dict[t] / num_tokens\n",
    "\n",
    "    A_2[ikili] = tokens_dict  # A2'deki value'ları artık list değil; dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t in A_2[(\"bir\", \"mavi\")]:\n",
    "    if i == 5:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "    print(t, A_2[(\"bir\", \"mavi\")][t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soz_yaz_2(satir_sayisi):\n",
    "    satirlar = []\n",
    "    for i in range(satir_sayisi):\n",
    "        satir = []\n",
    "        t0 = kelime_sec(A_0)\n",
    "        satir.append(t0)\n",
    "\n",
    "        t1 = kelime_sec(A_1[t0])\n",
    "        if t1 == satir_sonu:\n",
    "            satirlar.append(\" \".join(satir))\n",
    "            continue\n",
    "\n",
    "        satir.append(t1)\n",
    "        \n",
    "        while True:\n",
    "            t_1 = satir[-1]\n",
    "            t_2 = satir[-2]\n",
    "            t = kelime_sec(A_2[(t_2, t_1)])\n",
    "            if t == satir_sonu:\n",
    "                satirlar.append(\" \".join(satir))\n",
    "                break\n",
    "            satir.append(t)\n",
    "            \n",
    "    return \"\\n\".join(satirlar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soz_yaz_2(8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a508892ad0418bbbef2f3796edd4c06527622cb95cdcc5e9525e8332085ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
