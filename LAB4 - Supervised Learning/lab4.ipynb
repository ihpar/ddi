{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"turkish_song_lyrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.singer.value_counts()[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singer_0 = \"Zeki Müren\"\n",
    "singer_1 = \"Müslüm Gürses\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarkilar_0 = df[df[\"singer\"] == singer_0]\n",
    "sarkilar_1 = df[df.singer == singer_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sarkilar_0), len(sarkilar_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarkilar_0.singer.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarkilar_1.singer.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarkilar_0 = sarkilar_0.lyrics.to_numpy()\n",
    "sarkilar_1 = sarkilar_1.lyrics.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(singer_0, \"ilk sarkisi:\\n\\n\")\n",
    "print(sarkilar_0[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(singer_1, \"ilk sarkisi:\\n\\n\")\n",
    "print(sarkilar_1[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarkilar = [sarkilar_0, sarkilar_1]\n",
    "sarkicilar = [singer_0, singer_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satirlar = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sarki_seti: bir sarkiciya ait tum sarkilar\n",
    "for i, sarki_seti in enumerate(sarkilar):\n",
    "    for sarki in sarki_seti:  # sarki: bir sarkiciya ait sarki setindeki her bir sarki\n",
    "        for satir in sarki.split(\"\\n\"):\n",
    "            # satiri \"Hey! Naber?\"den \"hey naber\"e donusturuyoruz\n",
    "            satir = satir.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            satirlar.append(satir)\n",
    "            labels.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satirlar[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satirlar[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(satirlar), len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    satirlar, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train), len(X_test), len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(X_train[i], \"::\", y_train[i], \"::\", sarkicilar[y_train[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(X_test[i], \"::\", y_test[i], \"::\", sarkicilar[y_test[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = {}  # kelime dağarcığı (vocab.) oluşturuyoruz\n",
    "w2i[\"<UNK>\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "for satir in X_train:\n",
    "    tokens = satir.split()\n",
    "    for token in tokens:\n",
    "        if token not in w2i:\n",
    "            w2i[token] = index\n",
    "            index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(w2i.items())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w2i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w2i[\"hey\"], w2i[\"cânım\"], w2i[\"ömrüm\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"hey cânım hey ömrüm hey\" satirini [14, 15, 14, 16, 14] listesine dönüştüreceğiz\n",
    "X_train_int = []\n",
    "X_test_int = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train setindeki text satirlari, int satirlara donusturuyoruz\n",
    "for satir in X_train:\n",
    "    satir_int = []\n",
    "    tokens = satir.split()\n",
    "    for token in tokens:\n",
    "        satir_int.append(w2i[token])\n",
    "\n",
    "    X_train_int.append(satir_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test setindeki satirlari, int satirlara donusturuyoruz\n",
    "for satir in X_test:\n",
    "    satir_int = []\n",
    "    tokens = satir.split()\n",
    "    for token in tokens:\n",
    "        # eğer test setindeki bir token, train setinin sozlugunde w2i bulunmuyorsa\n",
    "        # bu token için <UNK> tag'ine karsilik gelen 0 degerini atiyoruz\n",
    "        satir_int.append(w2i.get(token, 0))\n",
    "\n",
    "    X_test_int.append(satir_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_int[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int_ZM = []  # sadece Zeki Müren'e ait satirlar\n",
    "for i, label in enumerate(y_train):\n",
    "    if label == 0:  # 0 == Zeki Müren\n",
    "        X_train_int_ZM.append(X_train_int[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_int_ZM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0s = [l for l in y_train if l == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train_0s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int_ZM[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int_MG = []  # Sadece Müslüm Baba'ya ait satirlar\n",
    "for i, label in enumerate(y_train):\n",
    "    if label == 1:  # 1 == Müslüm Gürses\n",
    "        X_train_int_MG.append(X_train_int[i])\n",
    "\n",
    "print(len(X_train_int_MG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(w2i)  # dagarcik boyutu (vocab. size)\n",
    "print(M)\n",
    "\n",
    "# Zeki Müren modeli\n",
    "pi_0 = np.ones(M)\n",
    "A_0 = np.ones((M, M))\n",
    "\n",
    "# Müslüm Gürses modeli\n",
    "pi_1 = np.ones(M)\n",
    "A_1 = np.ones((M, M))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_markov_model(satirlar_int, pi, A):\n",
    "    for satir_int in satirlar_int:  # satir_int: [5928, 4336, 1535, 4397, 802]\n",
    "        for i, token_index in enumerate(satir_int):  # i: 0, index: 5928\n",
    "            if i == 0:\n",
    "                # satir basindaysak, token'i pi'ye ekle\n",
    "                pi[token_index] += 1\n",
    "            else:\n",
    "                # satir basinda degilsek,\n",
    "                # bir onceki token'dan simdiki token'a gecis frekansini 1 arttir\n",
    "                A[satir_int[i - 1], token_index] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_markov_model(X_train_int_ZM, pi_0, A_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_markov_model(X_train_int_MG, pi_1, A_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1[:5, :15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizasyon\n",
    "pi_0 = pi_0 / pi_0.sum()\n",
    "pi_1 = pi_1 / pi_1.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_1[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "\n",
    "test2 = test.sum(axis=0)\n",
    "\n",
    "test3 = test.sum(axis=1)\n",
    "\n",
    "test4 = test.sum(axis=1, keepdims=True)\n",
    "\n",
    "print(\"original\")\n",
    "print(test)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"sum(axis=0)\")\n",
    "print(test2)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"sum(axis=1)\")\n",
    "print(test3)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "print(\"sum(axis=1, keepdims=True)\")\n",
    "print(test4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_0 = A_0 / A_0.sum(axis=1, keepdims=True)\n",
    "A_1 = A_1 / A_1.sum(axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pi_0 = np.log(pi_0)\n",
    "log_A_0 = np.log(A_0)\n",
    "\n",
    "log_pi_1 = np.log(pi_1)\n",
    "log_A_1 = np.log(A_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pi_1[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_A_1[:5, :4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0 = sum(y == 0 for y in y_train)  # ZM'e ait satirlarin sayisi\n",
    "count_1 = sum(y == 1 for y in y_train)  # MG'e ait satirlarin sayisi\n",
    "\n",
    "total = len(y_train)  # train setindeki toplam satir sayisi\n",
    "\n",
    "# prior'lari hesapla\n",
    "p_0 = count_0 / total\n",
    "log_p_0 = np.log(p_0)\n",
    "\n",
    "p_1 = count_1 / total\n",
    "log_p_1 = np.log(p_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_0, p_1, log_p_0, log_p_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_prob(input, clas):\n",
    "    \"\"\" \n",
    "    input'un verilen class'a ait olma olasiliginin log degerini hesaplar\n",
    "\n",
    "    örn input: [1, 3, 2, 7, ...] \n",
    "    örn clas: 0 veya 1\n",
    "    \"\"\"\n",
    "    pi = log_pi_0\n",
    "    A = log_A_0\n",
    "    prior = log_p_0\n",
    "\n",
    "    if clas == 1:\n",
    "        pi = log_pi_1\n",
    "        A = log_A_1\n",
    "        prior = log_p_1\n",
    "\n",
    "    log_prob = 0\n",
    "    for i, word_index in enumerate(input):\n",
    "        if i == 0:\n",
    "            log_prob += pi[word_index]\n",
    "        else:\n",
    "            log_prob += A[input[i - 1], word_index]\n",
    "\n",
    "    log_prob += prior\n",
    "    return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_int[0], y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_prob(X_train_int[0], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_prob(X_train_int[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    predictions = []\n",
    "    for input in inputs:\n",
    "        probas = [compute_log_prob(input, 0), compute_log_prob(input, 1)]\n",
    "        prediction = np.argmax(probas)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = predict(X_train_int)\n",
    "predictions_test = predict(X_test_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = np.array(predictions_train)\n",
    "predictions_test = np.array(predictions_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train == y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accu = np.mean(predictions_train == y_train)\n",
    "test_accu = np.mean(predictions_test == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy:\", train_accu)\n",
    "print(\"Test accuracy:\", test_accu)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a508892ad0418bbbef2f3796edd4c06527622cb95cdcc5e9525e8332085ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
